{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Part 4 - Generating Dataset 2 Using 3 Different Gaussian Distributions \n",
      "\n",
      "Training Data Generated. See: generated_data/DS2_train.csv\n",
      "Testing Data Generated. See: generated_data/DS2_test.csv \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "\n",
    "POS_MEAN_1 = 'data/DS2_c1_m1.txt'\n",
    "POS_MEAN_2 = 'data/DS2_c1_m2.txt'\n",
    "POS_MEAN_3 = 'data/DS2_c1_m3.txt'\n",
    "NEG_MEAN_1 = 'data/DS2_c2_m1.txt'\n",
    "NEG_MEAN_2 = 'data/DS2_c2_m2.txt'\n",
    "NEG_MEAN_3 = 'data/DS2_c2_m3.txt'\n",
    "COV_1 = 'data/DS2_Cov1.txt'\n",
    "COV_2 = 'data/DS2_Cov2.txt'\n",
    "COV_3 = 'data/DS2_Cov3.txt'\n",
    "TRAIN_DATA = 'generated_data/DS2_train.csv'\n",
    "TEST_DATA = 'generated_data/DS2_test.csv'\n",
    "\n",
    "''' Part 4 '''\n",
    "print('Part 4 - Generating Dataset 2 Using 3 Different Gaussian Distributions \\n')\n",
    "# Prepare Data\n",
    "mean0_1 = pd.read_csv(NEG_MEAN_1, header=None)\n",
    "mean1_1 = pd.read_csv(POS_MEAN_1, header=None)\n",
    "mean0_2 = pd.read_csv(NEG_MEAN_2, header=None)\n",
    "mean1_2 = pd.read_csv(POS_MEAN_2, header=None)\n",
    "mean0_3 = pd.read_csv(NEG_MEAN_3, header=None)\n",
    "mean1_3 = pd.read_csv(POS_MEAN_3, header=None)\n",
    "cov_1 = pd.read_csv(COV_1, header=None)\n",
    "cov_2 = pd.read_csv(COV_2, header=None)\n",
    "cov_3 = pd.read_csv(COV_3, header=None)\n",
    "mean0_1.drop([20], axis=1, inplace=True)\n",
    "mean1_1.drop([20], axis=1, inplace=True)\n",
    "cov_1.drop([20], axis=1, inplace=True)\n",
    "mean0_2.drop([20], axis=1, inplace=True)\n",
    "mean1_2.drop([20], axis=1, inplace=True)\n",
    "cov_2.drop([20], axis=1, inplace=True)\n",
    "mean0_3.drop([20], axis=1, inplace=True)\n",
    "mean1_3.drop([20], axis=1, inplace=True)\n",
    "cov_3.drop([20], axis=1, inplace=True)\n",
    "\n",
    "# Generate samples using gaussian distribution\n",
    "data0_1 = pd.DataFrame(np.random.multivariate_normal(mean0_1.as_matrix()[0], cov_1.values, 200))\n",
    "data1_1 = pd.DataFrame(np.random.multivariate_normal(mean1_1.as_matrix()[0], cov_1.values, 200))\n",
    "data0_2 = pd.DataFrame(np.random.multivariate_normal(mean0_2.as_matrix()[0], cov_2.values, 840))\n",
    "data1_2 = pd.DataFrame(np.random.multivariate_normal(mean1_2.as_matrix()[0], cov_2.values, 840))\n",
    "data0_3 = pd.DataFrame(np.random.multivariate_normal(mean0_3.as_matrix()[0], cov_3.values, 960))\n",
    "data1_3 = pd.DataFrame(np.random.multivariate_normal(mean1_3.as_matrix()[0], cov_3.values, 960))\n",
    "data0_1[20] = 0\n",
    "data1_1[20] = 1\n",
    "data0_2[20] = 0\n",
    "data1_2[20] = 1\n",
    "data0_3[20] = 0\n",
    "data1_3[20] = 1\n",
    "\n",
    "# Split data into test and training\n",
    "msk = np.random.rand(len(data0_1)) < 0.7\n",
    "train_data0_1 = data0_1.loc[msk]\n",
    "test_data0_1 = data0_1.loc[~msk]\n",
    "msk = np.random.rand(len(data1_1)) < 0.7\n",
    "train_data1_1 = data1_1.loc[msk]\n",
    "test_data1_1 = data1_1.loc[~msk]\n",
    "msk = np.random.rand(len(data0_2)) < 0.7\n",
    "train_data0_2 = data0_2.loc[msk]\n",
    "test_data0_2 = data0_2.loc[~msk]\n",
    "msk = np.random.rand(len(data1_2)) < 0.7\n",
    "train_data1_2 = data1_2.loc[msk]\n",
    "test_data1_2 = data1_2.loc[~msk]\n",
    "msk = np.random.rand(len(data0_3)) < 0.7\n",
    "train_data0_3 = data0_3.loc[msk]\n",
    "test_data0_3 = data0_3.loc[~msk]\n",
    "msk = np.random.rand(len(data1_3)) < 0.7\n",
    "train_data1_3 = data1_3.loc[msk]\n",
    "test_data1_3 = data1_3.loc[~msk]\n",
    "\n",
    "# Put both classes together in single data set\n",
    "train_data = pd.concat([train_data0_1, train_data1_1, train_data0_2, train_data1_2, train_data0_3, train_data1_3], ignore_index=True)\n",
    "test_data = pd.concat([test_data0_1, test_data1_1, test_data0_2, test_data1_2, test_data0_3, test_data1_3], ignore_index=True)\n",
    "train_data.to_csv(TRAIN_DATA)\n",
    "test_data.to_csv(TEST_DATA)\n",
    "\n",
    "print('Training Data Generated. See: {}'.format(TRAIN_DATA))\n",
    "print('Testing Data Generated. See: {} \\n'.format(TEST_DATA))\n",
    "\n",
    "# Create variables for future usage\n",
    "train_data0 = pd.DataFrame(train_data[train_data[20] == 0])\n",
    "train_data1 = pd.DataFrame(train_data[train_data[20] == 1])\n",
    "test_output = test_data[20]\n",
    "train_output = train_data[20]\n",
    "\n",
    "# Drop the outputs\n",
    "train_data0.drop([20], axis=1, inplace=True)\n",
    "train_data1.drop([20], axis=1, inplace=True)\n",
    "test_data.drop([20], axis=1, inplace=True)\n",
    "train_data.drop([20], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Part 2 - LDA Model Using Maximum Likelihood Approach \n",
      "\n",
      "w0:  -0.08382431667082715 \n",
      "\n",
      "w1: [-0.036121070473366684, 0.016843081807145055, 0.006689797742290029, -0.037607865056006745, 0.05312292616958406, 0.061027499793217886, -0.09028457452526403, 0.11140215822624577, -0.029867257675947535, -0.03358809136577283, 0.05297192396415256, 0.06418430227548107, 0.0439929246741877, -0.026038907549131053, -0.028747123378560294, -0.010108810575986421, 0.01577340396191533, -0.03080936471329309, -0.04549991069995683, -0.003958605805103335]\n",
      "\n",
      "F Measure:  0.5185185185185185\n",
      "Accuracy:  0.49294605809128633\n",
      "Precision:  0.4845360824742268\n",
      "Recall:  0.5576271186440678 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "''' Part 5.1 '''\n",
    "print('Part 2 - LDA Model Using Maximum Likelihood Approach \\n')\n",
    "\n",
    "# Find max probability\n",
    "prob0 = float(len(train_data0)) / float(len(train_data0) + len(train_data1))\n",
    "prob1 = 1.0 - prob0\n",
    "\n",
    "# Find mean\n",
    "mean0 = np.array(train_data0.mean())\n",
    "mean1 = np.array(train_data1.mean())\n",
    "\n",
    "# Find covariance matrix\n",
    "diff0 = np.array(train_data0 - mean0)\n",
    "diff1 = np.array(train_data1 - mean1)\n",
    "cov = (np.matmul(diff0.T, diff0) + np.matmul(diff1.T, diff1)) / float(len(train_data0) + len(train_data1))\n",
    "\n",
    "# Compute coefficients\n",
    "w0 = math.log(prob0) - math.log(prob1) - 0.5 * (np.matmul(np.matmul(mean0.T, np.linalg.pinv(cov)), mean0) - np.matmul(np.matmul(mean1.T, np.linalg.pinv(cov)), mean1))\n",
    "w1 = np.matmul(np.linalg.pinv(cov), mean0 - mean1)\n",
    "print(\"w0: \", w0, '\\n')\n",
    "print(\"w1: \" + str([i for i in w1]) + \"\\n\")\n",
    "\n",
    "# Compute output prediction\n",
    "pred_output = np.matmul(test_data, w1) + w0\n",
    "\n",
    "# Set prediction to 0 or 1 based on decision boundary\n",
    "pred_output[pred_output > 0] = 0\n",
    "pred_output[pred_output < 0] = 1\n",
    "\n",
    "# Compute confusion matrix\n",
    "confusion = [[0, 0], [0, 0]] # [[tp, fp],[fn, tn]]\n",
    "for i in range(len(test_output)):\n",
    "    true_value = test_output[i]\n",
    "    pred_value = pred_output[i]\n",
    "    if pred_value == 1:\n",
    "        if pred_value == true_value:\n",
    "            confusion[0][0] += 1\n",
    "        else:\n",
    "            confusion[0][1] += 1\n",
    "    if pred_value == 0:\n",
    "        if pred_value == true_value:\n",
    "            confusion[1][1] += 1\n",
    "        else:\n",
    "            confusion[1][0] += 1\n",
    "tp = confusion[0][0]\n",
    "fp = confusion[0][1]\n",
    "fn = confusion[1][0]\n",
    "tn = confusion[1][1]\n",
    "\n",
    "# Compute result\n",
    "accuracy = (tp + tn) / (tp + tn + fp + fn)\n",
    "precision = tp / (tp + fp)\n",
    "recall = tp / (tp + fn)\n",
    "f = 2 * precision * recall / (precision + recall)\n",
    "\n",
    "print('F Measure: ', f)\n",
    "print('Accuracy: ', accuracy)\n",
    "print('Precision: ', precision)\n",
    "print('Recall: ', recall, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Part 3 - k-NN Classifier \n",
      "\n",
      "K Value - Accuracy\n",
      "1 - 0.5228215767634855\n",
      "2 - 0.5203319502074689\n",
      "3 - 0.5219917012448133\n",
      "4 - 0.5161825726141079\n",
      "5 - 0.5443983402489626\n",
      "6 - 0.5369294605809128\n",
      "7 - 0.5427385892116182\n",
      "8 - 0.5302904564315353\n",
      "9 - 0.5203319502074689\n",
      "10 - 0.5170124481327801\n",
      "11 - 0.5236514522821577\n",
      "12 - 0.5269709543568465\n",
      "13 - 0.5385892116182572\n",
      "14 - 0.5236514522821577\n",
      "15 - 0.5261410788381743\n",
      "16 - 0.5261410788381743\n",
      "17 - 0.5170124481327801\n",
      "18 - 0.5203319502074689\n",
      "19 - 0.5195020746887967\n",
      "20 - 0.5161825726141079\n",
      "21 - 0.5195020746887967\n",
      "22 - 0.5170124481327801\n",
      "23 - 0.5311203319502075\n",
      "24 - 0.5145228215767634\n",
      "\n",
      "Best K Value:  5 \n",
      "\n",
      "F Measure:  0.5367088607594936\n",
      "Accuracy:  0.5443983402489626\n",
      "Precision:  0.534453781512605\n",
      "Recall:  0.5389830508474577 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "''' Part 5.2 '''\n",
    "print('Part 3 - k-NN Classifier \\n')\n",
    "\n",
    "# Variables to keep track of result from each step\n",
    "confusion_steps = []\n",
    "accuracy_steps = []\n",
    "\n",
    "# Perform knn classifier\n",
    "print('K Value - Accuracy')\n",
    "for i in range(1, 25):\n",
    "    confusion = [[0, 0], [0, 0]]\n",
    "    for j in range(len(test_data)):\n",
    "        distances = np.array(np.power(abs(train_data.sub(np.array(np.array(test_data.loc[[j], :])[0]))), 2).sum(axis=1))\n",
    "        closest_neighbours = np.array([train_output[j] for j in np.argpartition(distances, i)[:i]])\n",
    "        pred_value = 1 if closest_neighbours.mean() > 0.5 else 0\n",
    "        true_value = test_output[j]\n",
    "        if pred_value == 1:\n",
    "            if pred_value == true_value:\n",
    "                confusion[0][0] += 1\n",
    "            else:\n",
    "                confusion[0][1] += 1\n",
    "        if pred_value == 0:\n",
    "            if pred_value == true_value:\n",
    "                confusion[1][1] += 1\n",
    "            else:\n",
    "                confusion[1][0] += 1\n",
    "    tp = confusion[0][0]\n",
    "    fp = confusion[0][1]\n",
    "    fn = confusion[1][0]\n",
    "    tn = confusion[1][1]\n",
    "    accuracy = (tp + tn) / (tp + tn + fp + fn)\n",
    "    confusion_steps.append(confusion)\n",
    "    accuracy_steps.append(accuracy)\n",
    "    print('{} - {}'.format(i, accuracy))\n",
    "\n",
    "# Calculate optimal k\n",
    "k_index = accuracy_steps.index(max(accuracy_steps))\n",
    "print(\"\\nBest K Value: \", k_index + 1, '\\n')\n",
    "\n",
    "# Calculate metrics\n",
    "confusion = confusion_steps[k_index]\n",
    "tp = confusion[0][0]\n",
    "fp = confusion[0][1]\n",
    "fn = confusion[1][0]\n",
    "tn = confusion[1][1]\n",
    "accuracy = (tp + tn) / (tp + tn + fp + fn)\n",
    "precision = tp / (tp + fp)\n",
    "recall = tp / (tp + fn)\n",
    "f = 2 * precision * recall / (precision + recall)\n",
    "print('F Measure: ', f)\n",
    "print('Accuracy: ', accuracy)\n",
    "print('Precision: ', precision)\n",
    "print('Recall: ', recall, '\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
